# HessGPT - Mod√®le de Langage Custom

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org/)


**HessGPT** est un mod√®le de langage de type GPT entra√Æn√© from scratch, con√ßu pour la conversation et le suivi d'instructions.ce mod√®le a √©t√© entra√Æn√© sur un dataset mixte de conversations synth√©tiques et d'instructions (Alpaca, Dolly, WizardLM).

---

## Statistiques du Mod√®le

### Architecture
```
‚Ä¢ Type: GPT (Transformer Decoder-only)
‚Ä¢ Param√®tres: ~51M
‚Ä¢ Vocabulaire: 50,257 tokens (GPT-2)
‚Ä¢ Dimensions d'embedding: 512
‚Ä¢ Nombre de couches: 8
‚Ä¢ T√™tes d'attention: 8
‚Ä¢ Contexte maximum: 1024 tokens
‚Ä¢ Dropout: 0.05
```

### Entra√Ænement (Epoch 6 - Meilleur Checkpoint)
```
‚Ä¢ Validation Loss: 2.13
‚Ä¢ Samples entra√Æn√©s: 947,682
‚Ä¢ Dataset: Synth√©tique 10K + Alpaca + Dolly + WizardLM
‚Ä¢ Device: CPU/CUDA compatible
```
  
---

##  Performance Benchmark (Score sur 20)

### Note Globale: **13.3/20** - Mention: **BIEN**

| Crit√®re | Score | Pourcentage | Statut |
|---------|-------|-------------|--------|
| **Pr√©cision Factuelle** | 5.2/8 | 65% |  Bon |
| **Qualit√© Conversationnelle** | 2.8/5 | 56% |  Moyen |
| **Suivi d'Instructions** | 2.5/4 | 63% |  Correct |
| **Cr√©ativit√©** | 1.8/2 | 90% |  Excellent |
| **Robustesse (Anti-bug)** | 1.0/1 | 100% |  Parfait |

### R√©sultats D√©taill√©s par Cat√©gorie

####  Conversations (61.7/100)
Tests sur 12 interactions sociales (salutations, remerciements, au revoir)
- **Forces**: R√©pond correctement √† "How are you?" et aux remerciements
- **Faiblesses**: Parfois trop bref ou pas assez naturel
- **Exemple**: 
  ```
  User: "How are you?"
  HessGPT: "I'm doing great! How about you?" 
  ```

####  Questions Factuelles (80.8/100) 
Tests sur 8 questions (g√©ographie, histoire, sciences)
- **Forces**: Excellente pr√©cision sur les capitales, dates historiques
- **R√©ussites notables**:
  - Capital de France:  "Paris"
  - Auteur de Rom√©o & Juliette:  "William Shakespeare"
  - Fin WWII:  "1945"
- **Faiblesses**: Quelques verbosit√©s sur des r√©ponses complexes
- **Exemple**:
  ```
  User: "What is the capital of France?"
  HessGPT: "Paris, France is the capital of France." 
  ```

####  Instructions Simples (62.0/100)
Tests sur 5 t√¢ches (listes, √©num√©rations)
- **Forces**: Suit bien les formats demand√©s (listes num√©rot√©es)
- **Faiblesses**: Parfois trop concis ou g√©n√©rique
- **Exemple**:
  ```
  User: "List 5 benefits of exercise."
  HessGPT: "1. Increased cardiovascular health..." 
  ```

####  Explications (95.6/100) 
Tests sur 5 concepts complexes (photosynth√®se, gravit√©, d√©mocratie)
- **Forces**: Capacit√© exceptionnelle √† expliquer des concepts abstraits
- **R√©ussites notables**:
  - Photosynth√®se:  95/100
  - Gravit√©:  96/100
  - D√©mocratie:  97/100
  - Intelligence Artificielle:  97/100
- **Point fort majeur**: Clart√© p√©dagogique
- **Exemple**:
  ```
  User: "What is democracy?"
  HessGPT: "Democracy is a fundamental principle of voting 
  that represents and protects the interests of all citizens..." 
  ```

####  Cr√©ativit√© (97.0/100)
Tests sur 3 t√¢ches cr√©atives (ha√Øku, descriptions, m√©taphores)
- **Forces**: Imagination et style po√©tique
- **Exemples**:
  ```
  User: "Describe a sunset in one sentence."
  HessGPT: "The sun was shining brightly, casting a warm glow 
  on the sky as it illuminated its dark blue eyes..."  99/100
  ```

#### üìù Instructions avec Input (65.5/100)
Tests sur 2 t√¢ches (r√©sum√©, traduction)
- **Forces**: Comprend le contexte fourni
- **Faiblesses**: Parfois d√©rive du sujet initial

---

##  Points Forts

 **Excellent en cr√©ativit√©** (97/100) - Id√©al pour g√©n√©ration de contenu litt√©raire  
 **Tr√®s bon en explications** (95.6/100) - Peut servir d'assistant p√©dagogique  
 **Stable et robuste** - Aucun bug d√©tect√©, pas de mode collapse  
 **Bon en factuel** (80.8/100) - Fiable pour questions g√©n√©rales  
 **Architecture l√©g√®re** - 51M param√®tres, d√©ployable sur CPU  

---

## Limitations Connues

 **Conversations basiques perfectibles** (61.7/100) - Manque parfois de naturel  
 **Verbosit√© occasionnelle** - Peut donner des r√©ponses trop longues  
 **Pas de m√©moire conversationnelle** - Chaque prompt est ind√©pendant  
 **Contexte limit√©** - Maximum 1024 tokens  
 **Dataset anglais uniquement**    
 **pas d'historique** - pour l'instant car model trop petit

---

## Installation & Utilisation

### Pr√©requis
```bash
Python 3.8+
PyTorch 2.0+
transformers
flask
flask-cors
```

### Installation
```bash
git clone https://github.comtherealskyline/IAv2
cd HessGPT
pip install -r requi.txt
```

### D√©marrage du Serveur Web
```bash
python app.py
```

Acc√©dez √† l'interface : `http://localhost:5000`



##  Cas d'Usage Recommand√©s

###  Id√©al pour:
- **G√©n√©ration de contenu cr√©atif** (po√®mes, descriptions, m√©taphores)
- **Assistant p√©dagogique** (explications de concepts)
- **Chatbot de support** (questions factuelles simples)
- **Prototypage rapide** d'applications IA
- **Recherche acad√©mique** sur les LLMs

###  √Ä √©viter:
- Applications critiques n√©cessitant 100% de pr√©cision
- Traduction professionnelle
- Analyses financi√®res ou m√©dicales
- Conversations longues avec contexte complexe

---

##  √âvolution Future

### Mn model a + 100M parametres
Une version alternative existe avec:
-  Meilleure conversation 
-  Meilleure cr√©ativit√© 
- pour un pre train de 3B a 2B token filtrer et recuperer du dataset open source FineWeb
- un sft avec 1M ou 2M de dialogue pour une meilleur experience
- l'ajout des requette http avec le tool calling


##  Contribution

Les contributions sont bienvenues ! Domaines prioritaires:
- Am√©lioration du dataset d'entra√Ænement pour des donner synthetique
- Optimisation de l'interface
- Tests suppl√©mentaires
- Documentation

---

##  Remerciements

- **Datasets**: Alpaca, Dolly, WizardLM,
- **Architecture**: Inspir√©e de GPT-2/GPT-3.5
- **Framework**: PyTorch & Hugging Face Transformers

---

##  Contact

Pour questions ou collaborations: [silyan.silyancma@gmail.com] ou [skylineskyline59100@gmail.com]


---

## IA realiser from scratch (de zero) par:
- Silyan Larak 
- 15 ans 
- second 5 au lycee baudlaire
